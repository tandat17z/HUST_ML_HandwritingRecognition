{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\HUST\\20232\\ML\\Project_OCR\\HandwritingRecognition\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, nclass, num_hidden, dropout = 0.1):\n",
    "        print('>>>> use Crnn-------------\\n')\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        ks = [ 3,  3,   3,   3,   3,   3,  2]\n",
    "        ss = [ 1,  1,   1,   1,   1,   1,  1]\n",
    "        ps = [ 1,  1,   1,   1,   1,   1,  0]\n",
    "        nm = [32, 64, 128, 128, 256, 256, 256]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "        def convRelu(i):\n",
    "            nIn = 1 if i == 0 else nm[i - 1] \n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "\n",
    "        # input : (C, H, W) - (1, 32, 512) /800\n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d((2, 2)))  # 32, 16, 256/ 400\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d((2, 2)))  # 64, 8, 128/ 200\n",
    "        convRelu(2) \n",
    "        convRelu(3) \n",
    "        cnn.add_module('pooling{0}'.format(2), nn.MaxPool2d((2, 1)))  # 128, 4, 128/ 200\n",
    "        convRelu(4)\n",
    "        convRelu(5) \n",
    "        cnn.add_module('pooling{0}'.format(3), nn.MaxPool2d((2, 1)))  # 256, 2, 128/ 200\n",
    "        convRelu(6)\n",
    "        self.cnn = cnn\n",
    "        self.dropout_cnn = nn.Dropout(dropout)\n",
    "    \n",
    "        # BiLSTM\n",
    "        self.biLSTM1 = nn.LSTM(nm[-1], num_hidden, bidirectional=True, batch_first = True)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.biLSTM2 = nn.LSTM(num_hidden*2, num_hidden, bidirectional=True, batch_first = True)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # Linear\n",
    "        self.linear = nn.Linear(num_hidden * 2, nclass)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "        x1 = self.cnn(input) # b, 256, 1, 127\n",
    "        x1 = self.dropout_cnn(x1)\n",
    "        x1 = torch.squeeze(x1, 2) # b, 256, 127\n",
    "        x1 = x1.permute(0, 2, 1)  # b, 127, 256\n",
    "\n",
    "        x2, _  = self.biLSTM1(x1) # b, 127, num_hidden*2\n",
    "        x2 = self.dropout1(x2) \n",
    "\n",
    "        x3, _ = self.biLSTM2(x2) # b, 127, num_hidden*2\n",
    "        x3 = self.dropout2(x3)\n",
    "\n",
    "        out = self.linear(x2) # b, 127, num_class\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> use Crnn-------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (conv0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pooling0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pooling1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (pooling2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu4): ReLU(inplace=True)\n",
       "    (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu5): ReLU(inplace=True)\n",
       "    (pooling3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv6): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (batchnorm6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu6): ReLU(inplace=True)\n",
       "  )\n",
       "  (dropout_cnn): Dropout(p=0.1, inplace=False)\n",
       "  (biLSTM1): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (biLSTM2): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (linear): Linear(in_features=256, out_features=151, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CRNN(151, 128, 0.1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 191, 151])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(64, 1, 32, 768)\n",
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tandat17z",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
