{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\HUST\\20232\\ML\\Project_OCR\\HandwritingRecognition\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from utils.StrLabelConverter import StrLabelConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = open(os.path.join('data/mychar.txt')).read()\n",
    "convert = StrLabelConverter(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert.numClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tandat17z\\anaconda3\\envs\\env_tandat17z\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetImg_v2('data/data_v1/train/img', 'data/data_v2/train/label', 800, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=16,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import GetInputCTCLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 44, 134,   1,  14,  22,  19,   1, 101, 107, 141,  64,  57,   1,  42,\n",
       "          71,  51,  64,  57,   1,  45,  68,  71,  64,  57,   9,   1,  41,  58,\n",
       "         107, 141,  64,  57,   1,  42,  71,  51,  64,  57,   1,  45,  68,  71,\n",
       "          64,  57,   9,   1,  42,  71, 116,  64,   1,  33,  82,   1, 100,  93,\n",
       "          64,  57,   9,   1,  33,  82,   1,  39, 139,  59,  41,  58, 107, 141,\n",
       "          64,  57,   1,  38,  51,  59,   1,  29, 131,  53,  58,   9,   1,  42,\n",
       "          71, 116,  64,   1,  28, 113,  71,   1,  32,  59, 111,  74,   9,   1,\n",
       "          33,  82,   1,  39, 139,  59,  38, 122,   1,  64, 111,  71,   1,  53,\n",
       "         105,  63,   1,  70,  58, 105,  63,   1,  64,  57,  65,  64,   1,  53,\n",
       "          58,  65,   1,  53, 109,   1,  57,  59,  51,   1, 101,  89,  64,  58,\n",
       "          11,  44, 134,   1,  14,  19,   1, 101, 107, 141,  64,  57,   1,  15,\n",
       "          14,  12,  21,   9,   1,  41,  58, 107, 141,  64,  57,   1,  41,  58,\n",
       "         148,   1,  33,  82,   9,   1,  45,  41,  11,   1,  41,  58,  51,  64,\n",
       "           1,  43,  51,  64,  57,  10,  45,  58,  83,  66,   1,  28,  58,  82,\n",
       "          63,   9,   1,  39,  59,  64,  58,   1,  45,  58,  71, 116,  64,  19,\n",
       "          17,  16,   1,  39,  57,  93,   1,  42,  71,  74, 126,  64,   9,   1,\n",
       "          41,  58, 107, 141,  64,  57,   1,  26,  64,   1,  33, 109,  59,   1,\n",
       "          27, 117,  53,   9,   1,  42,  71, 116,  64,   1,  44, 105,  64,   1,\n",
       "          45,  68,  82,   9,   1, 100,  82,   1,  39, 120,  64,  57,  15,  13,\n",
       "           1,  41,  58, 107, 140,  53,   1,  45, 107, 141,  64,  57,   9,   1,\n",
       "          41,  58, 107, 141,  64,  57,   1,  41,  58, 107, 140,  53,   1,  37,\n",
       "          65,  64,  57,   9,   1,  45,  58,  82,  64,  58,   1,  66,  58, 134,\n",
       "           1,  39,  58,  51,   1,  45,  68,  51,  64,  57,   9,   1,  36,  58,\n",
       "          83,  64,  58,   1,  33,  91,  51,  49,  85,   1,  39,  51,  63,   1,\n",
       "          29, 107, 105,  64,  57,   9,   1,  33,  71,  74, 129,  64,   1,  39,\n",
       "          51,  63,   1,  45,  68, 154,  53,   9,   1,  39,  51,  63,   1, 100,\n",
       "         131,  64,  58,  44, 134,   1,  22,   1,  41,  58, 108,  63,   1,  44,\n",
       "         107,   1,  38, 108,  64,  58,   9,   1,  41,  58, 107, 141,  64,  57,\n",
       "           1,  45,  68,  82,  64,  57,   1,  45,  59, 126,  64,   9,   1,  42,\n",
       "          71, 116,  64,   1,  33,  65,  82,  64,   1,  36,  59, 125,  63,   9,\n",
       "           1,  33,  82,   1,  39, 139,  59,  36,  17,  21,  17,  12,  17,   1,\n",
       "          45,  68, 113,  64,   1,  28,  51,  65,   1,  47,  84,  64,   9,   1,\n",
       "          41,  58, 107, 141,  64,  57,   1,  49,  71,  84,  64,   1,  33,  82,\n",
       "           9,   1,  42,  71, 116,  64,   1,  45,  58,  51,  64,  58,   1,  36,\n",
       "          58,  88,   9,   1, 100,  82,   1,  39, 120,  64,  57, 111,  66,   1,\n",
       "          47, 102,  64,  58,   1,  37, 139,  53,   9,   1,  33,  71,  74, 129,\n",
       "          64,   1,  47, 102,  64,  58,   1,  45,  58, 108,  64,  58,   9,   1,\n",
       "          28, 113,  64,   1,  45,  58, 105,  45,  68, 123,   1,  55,  63,   1,\n",
       "          64,  93,   1, 101,  95,  51,   1,  70,  68,  65,  64,  57,   1,  69,\n",
       "          84,  64,   1,  64,  58,  82,   1,  68, 139,  64,  57,   1,  62, 140,\n",
       "          64,  11,  14,  22,  20,   1, 100,  59,  64,  58,   1,  27, 139,   1,\n",
       "          37, 102,  64,  58,   9,   1,  41,  58, 107, 141,  64,  57,   1,  15,\n",
       "          19,   9,   1,  42,  71, 116,  64,   1,  27,  89,  64,  58,   1,  45,\n",
       "          58, 108,  64,  58,   9,   1,  45,  41,   1,  33, 136,   1,  28,  58,\n",
       "          90,   1,  38,  59,  64,  58, 100,  59, 126,  71,   1,  67,  71,  51,\n",
       "          64,   1,  70,  68, 132,  64,  57,   1,  61,  58,  93,  64,  57,   1,\n",
       "          66,  58, 109,  59,   1,  62,  82,   1, 101,  59,   1, 101, 125,  64,\n",
       "           1, 101,  84,  71,  11,  15,  19,  21,   1,  45,  68, 113,  64,   1,\n",
       "          33, 107,  64,  57,   1, 100, 108,  65,   1,  27,   9,   1,  41,  58,\n",
       "         107, 141,  64,  57,   1,  14,  14,   9,   1,  42,  71, 116,  64,   1,\n",
       "          18,   9,   1,  45,  41,   1,  33, 136,   1,  28,  58,  90,   1,  38,\n",
       "          59,  64,  58,  45,  58, 152,  51,   1,  69, 134,   1,  14,  16,  22,\n",
       "          13,   9,   1, 111,  66,   1,  17,   9,   1,  49,  85,   1,  37, 107,\n",
       "         105,  64,  57,   1,  27,  89,  64,  58,   9,   1,  33,  71,  74, 129,\n",
       "          64,   1,  27, 125,  64,   1,  37, 150,  53,   9,   1,  37,  65,  64,\n",
       "          57,   1,  26,  64,  38,  84,  74,   1,  70,  68, 117,  64,  57,   1,\n",
       "          52, 136,  64,  57,   1,  52, 126,  64,  58,   1,  70,  68,  93,  59,\n",
       "           1,  54, 108,  70,   1,  61,  58, 117,  66,   1,  70,  68, 141,  59,\n",
       "          11], dtype=torch.int32),\n",
       " tensor([66, 38, 37, 68, 55, 65, 38, 60, 60, 38, 37, 60, 41, 54, 57, 39],\n",
       "        dtype=torch.int32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets, target_lengths = convert.encode(label)\n",
    "targets, target_lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mGetInputCTCLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\HUST\\20232\\ML\\Project_OCR\\HandwritingRecognition\\utils\\utils.py:9\u001b[0m, in \u001b[0;36mGetInputCTCLoss\u001b[1;34m(converter, preds, labels)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGetInputCTCLoss\u001b[39m(converter, preds, labels):\n\u001b[1;32m----> 9\u001b[0m     b, l, c \u001b[38;5;241m=\u001b[39m \u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m     10\u001b[0m     preds_ \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m     preds_lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(size\u001b[38;5;241m=\u001b[39m(b,), fill_value\u001b[38;5;241m=\u001b[39ml, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "GetInputCTCLoss(convert, convert.encode(label), convert.encode(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tandat17z",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
